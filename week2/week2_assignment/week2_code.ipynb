{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 1\n",
    "Remember from last week we discussed that skewness and kurtosis functions in statistical packages are often biased. Is your function biased? Prove or disprove your hypothesis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# First load all libraries needed to solve this problem, using \"pip install\" would be necessary if any libraries are reported missing in local environment.\n",
    "import numpy as np\n",
    "from scipy.stats import kurtosis, ttest_1samp, t, describe, norm, skew\n",
    "from math import sqrt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T02:27:59.311144Z",
     "start_time": "2023-09-07T02:27:59.310384Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current sample size is 100\n",
      "current sample round is 100\n",
      "current kurtosis is 0.27609453979299836 , num_kurts is 0\n",
      "for this kurtosis, we fail to reject null hypothesis and it can be unbiased\n",
      "\n",
      "current sample round is 1000\n",
      "current kurtosis is -0.5713283547961265 , num_kurts is 1\n",
      "for this kurtosis, we rejected null hypothesis and it is biased\n",
      "\n",
      "\n",
      "current sample size is 1000\n",
      "current sample round is 100\n",
      "current kurtosis is -0.015478581598906693 , num_kurts is 0\n",
      "for this kurtosis, we rejected null hypothesis and it is biased\n",
      "\n",
      "current sample round is 1000\n",
      "current kurtosis is -0.21022676762880943 , num_kurts is 1\n",
      "for this kurtosis, we fail to reject null hypothesis and it can be unbiased\n",
      "\n",
      "\n",
      "current sample size is 100000\n",
      "current sample round is 100\n",
      "current kurtosis is 9.732047303545599e-05 , num_kurts is 0\n",
      "for this kurtosis, we rejected null hypothesis and it is biased\n",
      "\n",
      "current sample round is 1000\n",
      "current kurtosis is -0.007573940323081452 , num_kurts is 1\n",
      "for this kurtosis, we rejected null hypothesis and it is biased\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_size = [100, 1000, 100000] # as we know, when sample size increases, the biased and unbiased parameters should converge to their true value, and we are interested in whether it is true, so we allow it to vary\n",
    "sample_round = [100, 1000] # as shown during class, with fewer sample rounds (we have less kurtosis to examine), we have less statistical power to detect bias, even if it exists, and we are also interested in whether it is true, so we also allow it to vary\n",
    "\n",
    "expected_kurt = 3\n",
    "threshold = 0.05\n",
    "for i in sample_size:\n",
    "    print(\"current sample size is\", i)\n",
    "    num_kurts = 0\n",
    "    reject_null = False\n",
    "    for j in sample_round:\n",
    "        print(\"current sample round is\", j)\n",
    "        kurts = np.empty(j) # initialize an empty dataframe of numbers = sample_round to store kurt calculated during this loop\n",
    "        data = np.random.normal(0, 1, i) # initialize random normal distributed data to calculate kurt\n",
    "        kurts[num_kurts] = kurtosis(data)\n",
    "        print(\"current kurtosis is\", kurts[num_kurts], \", num_kurts is\", num_kurts)\n",
    "        t_stat, p_val = ttest_1samp(kurts, expected_kurt)\n",
    "        if p_val < threshold:\n",
    "            reject_null = True\n",
    "            print(\"for this kurtosis, we rejected null hypothesis and it is biased\")\n",
    "        else:\n",
    "            reject_null = False\n",
    "            print(\"for this kurtosis, we fail to reject null hypothesis and it can be unbiased\")\n",
    "        print(\"\")\n",
    "\n",
    "        num_kurts += 1\n",
    "    print(\"\")\n",
    "\n",
    "# implementation of tests for skewness, and show biased and unbiased parameter for all\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-07T03:00:29.536404Z",
     "start_time": "2023-09-07T03:00:29.515280Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 2\n",
    "Fit the data in problem2.csv using OLS and calculate the error vector. Look at its distribution. How well does it fit the assumption of normally distributed errors? Fit the data using MLE given the assumption of normality. Then fit the MLE using the assumption of a T distribution of the errors. Which is the best fit? What are the fitted parameters of each and how do they compare? What does this tell us about the breaking of the normality assumption in regards to expected values in this case?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Problem 3\n",
    "Simulate AR(1) through AR(3) and MA(1) through MA(3) processes. Compare their ACF and PACF graphs. How do the graphs help us to identify the type and order of each process?"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
